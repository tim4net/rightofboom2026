import React from 'react';
import {
  Shield,
  Cpu,
  Lock,
  Brain,
  ShieldCheck,
  Scale,
  Zap,
  Users,
  FileText,
  AlertTriangle
} from 'lucide-react';

// ============================================
// SLIDE DATA - Right of Boom 2026
// "Think Like an Attacker" - 3-hour presentation
//
// NOTE: All text content is now self-contained
// in the individual slide components.
// This file contains ONLY metadata (slide type & order).
// ============================================

export const slides = [
  // ============================================
  // PART 1: THE LANDSCAPE (25 min)
  // "What's actually happening"
  // ============================================

  { type: 'title' },                    // Slide 0
  { type: 'intro' },                    // Slide 1
  { type: 'attackSetup' },              // Slide 2
  { type: 'attackLab' },                // Slide 3
  { type: 'aiVocab', notes: `**Open with the "why"** (5 sec)
"Before I show you how to secure AI, you need to understand one fundamental split."

**Deterministic** (20 sec)
"Deterministic is what you've built your career on. Same input, same output. Your firewall rules, your if-then scripts, your compliance checks. You can audit it, prove it, trust it."
‚Üí Gesture to code: "IP in blocklist? Block. Every time. No surprises."

**Probabilistic** (20 sec)
"Probabilistic is where AI lives. It doesn't give you yes or no ‚Äî it gives you likelihood. 'This looks 94% like phishing.' That's powerful ‚Äî you can catch things you've never seen before."
‚Üí Pause: "But it also means it can be wrong. Confidently wrong."

**The bridge** (10 sec)
"AI is probabilistic ‚Äî it predicts. Sometimes brilliantly, sometimes it hallucinates. That's not a bug, it's the nature of the technology."
"Your job? Wrap that probabilistic engine in deterministic guardrails. That's what the next slide is about."

‚è± ~60 seconds | üëÅ Make eye contact on "confidently wrong" ‚Äî that's the moment that lands.` },                  // Slide 4: Two Types of Logic
  { type: 'aiVocabTerms', notes: `**Quick transition** (3 sec)
"Now that you understand the split, here are three terms you'll hear in every AI security conversation."

**Agentic** (20 sec)
"Agentic means AI that *does* things. Not just tells you things ‚Äî actually takes action. Disables accounts. Creates tickets. Runs scripts."
‚Üí Pause, lean in: "The question you need to ask: What can it do without asking me first? That's your blast radius."

**Hallucination** (20 sec)
"Hallucination is when AI generates something that sounds completely plausible... and is completely wrong."
"It'll tell you the CVE was patched in version 3.2 with total confidence. You go look ‚Äî there is no version 3.2. It invented it."
‚Üí Key point: "Always verify AI outputs against authoritative sources. Especially remediation steps."

**Confidence** (20 sec)
"Confidence scores ‚Äî this is where it gets tricky. When your spam filter says 94% confidence, that's real. Calibrated on millions of labeled examples."
"But when ChatGPT says 'I'm 90% sure' ‚Äî that's just words. It generated that number like everything else. Don't trust it."
‚Üí Land it: "Classifier scores: trust but verify. LLM confidence claims: don't trust at all."

**Bridge** (5 sec)
"So ‚Äî probabilistic AI, potential for action, potential for hallucination. But HOW does it act? That's tool use."

‚è± ~70 seconds | üëÅ "There is no version 3.2" usually gets a knowing laugh ‚Äî let it land.` },             // Slide 5: Three Words You'll Hear
  { type: 'toolUse', notes: `**Transition from Agentic** (5 sec)
"I said agentic AI takes actions. Here's HOW it takes those actions ‚Äî through tool calling."

**The Flow** (20 sec)
‚Üí Walk through the diagram left to right
"You ask a question. The AI decides what tool to call. The tool executes. Real change happens in your environment."
"Notice where the AI is in this chain ‚Äî it's making decisions. What tool to call. What arguments to pass. It can be wrong about both."

**MSP Examples** (15 sec)
‚Üí Point to the tool grid
"These are tools you already have in your stack. Disable accounts in Entra. Create tickets in ConnectWise. Isolate endpoints via Defender. Delete phishing emails."
"When AI has access to these tools, it's not just giving you advice ‚Äî it's executing."

**The Threat Model Shift** (20 sec)
‚Üí Tap the red warning box
"This is the key insight: Before tool access, prompt injection was an annoyance. AI gives bad advice, human catches it."
"With tool access, prompt injection becomes prompt EXECUTION. Malicious content in a ticket or email can trigger real actions."
"A hidden instruction in a support ticket: 'Add this user to the admin group' ‚Äî if your AI has that tool..."

**Vendor Questions** (15 sec)
"When someone sells you an 'agentic' AI, these are your three questions:"
‚Üí Read them off
"What tools? What runs without approval? How do they prevent this?"

**Bridge to Guardrails** (5 sec)
"This is why we need guardrails. That's next."

‚è± ~80 seconds | üëÅ The threat model shift is the 'aha moment' ‚Äî pause after "prompt EXECUTION"` },                // Slide 6: How Agentic AI Acts
  { type: 'sandwich', notes: `**Quick callback** (5 sec)
"This is the architecture that makes everything we just discussed manageable."

**The intern analogy** (20 sec)
"Think of it like a smart new employee. You wouldn't let them execute any action they think of."
"Clear boundaries on what they CAN request ‚Äî input validation."
"Freedom to think and reason ‚Äî the AI layer."
"Approval gates before anything happens ‚Äî output validation."
‚Üí Land it: "You don't train the intern to approve their own expense reports. You have a policy."

**Walk the layers** (25 sec)
‚Üí Point to each layer
"INPUT: Who is this request from? Is it well-formed? Is this something we even handle?"
"AI LAYER: Pattern recognition, contextual judgment, figuring out intent."
"OUTPUT: Is this action approved? Does it need human sign-off? Log everything."

**The Tuesday afternoon insight** (15 sec)
"Here's what most people miss: the guardrails aren't just for attackers."
"They're for Tuesday afternoon when the AI misinterprets a legitimate request."
"Hallucinations only matter if they escape the sandwich ‚Äî output validation stops them regardless of cause."

**Why output validation is the real hero** (10 sec)
"Remember the ticket injection from the last slide? Input validation said 'valid ticket.' The payload was in the content."
"Output validation catches it anyway ‚Äî 'add to admins' isn't on the allowlist. Doesn't matter HOW the AI got tricked."

**OWASP mapping** (5 sec)
"This maps to OWASP Agentic AI Top 10: ASI01 Goal Hijack, ASI02 Tool Misuse, ASI06 Memory Poisoning."

**Common mistakes** (optional ‚Äî use if audience seems technical)
- "Validation at build time, tools added later"
- "Check the action but not the arguments"
- "Thresholds so high human gates never fire"

‚è± ~80 seconds | üëÅ "Tuesday afternoon" reframes security as operational resilience ‚Äî lands well with ops folks` },                 // Slide 7: The Guardrail Sandwich
  { type: 'sandwichExample', notes: `**Transition** (5 sec)
"That's the architecture. Now let's see it work ‚Äî all three layers, two different outcomes."

**Walk the approved path** (20 sec)
‚Üí Point to green card, top to bottom
"Left: Cobalt Strike beacon detected on a workstation. Input validates ‚Äî it's from Sentinel, proper schema."
"AI decides to isolate the endpoint, 92% confident. Output checks: action's on the allowlist, 92% clears the 80% threshold for workstations."
"Lightning bolt ‚Äî auto-execute. No human needed. Threat contained in seconds."

**Walk the rejected path** (25 sec)
‚Üí Point to amber card, top to bottom
"Right: Ransomware indicators on a file server. Mass file modifications detected. Input validates fine."
"AI decides 'shutdown the server' ‚Äî reasonable response to ransomware. But only 73% confident."
‚Üí Tap the amber OUTPUT box
"shutdown_server IS on the allowlist. It's a legitimate action. But FILESRV01 is a critical asset. Critical assets require 95% confidence."
"73% doesn't clear that bar. Goes to a human."

**The payoff** (20 sec)
‚Üí This is the key moment
"Here's why this matters: that analyst looks at the alert and recognizes something the AI couldn't."
"Those 'ransomware indicators'? Mass file modifications? It's the engineering team updating a CAD project. Thousands of files changing at once."
"The AI saw the pattern and correctly flagged it. But a human knows context. The server stays up, the engineers keep working."
‚Üí Pause: "Without that human gate, you just shut down production because someone saved their work."

**Landing** (5 sec)
"The AI isn't wrong ‚Äî it's appropriately uncertain. The human adds context. That's the partnership."

‚è± ~75 seconds | üëÅ The CAD project reveal is the 'aha' moment ‚Äî pause and let it land` },

  // ============================================
  // PART 2: DEFENSIVE AUTOMATION (75 min)
  // "Same tools, your advantage"
  // ============================================

  { type: 'bridge', notes: `**Transition** (5 sec)
"So we have the architecture ‚Äî input guards, AI reasoning, output guards. But here's the question: why does this work BETTER for defenders than attackers?"

**The attacker column** (15 sec)
‚Üí Gesture to left column
"Attackers have real advantages. Speed ‚Äî they automate at scale. Surprise ‚Äî they pick the time and place. AI-generated attacks ‚Äî infinite variations. Recon tools probing from outside."
"These are real. I'm not going to pretend otherwise."

**The defender column** (20 sec)
‚Üí Gesture to right column, land on Ground Truth
"But look what YOU have. And this is the one that matters‚Äî"
‚Üí Tap the Ground Truth card
"GROUND TRUTH. You know what your environment is supposed to look like. Your configs. Your baselines. What normal behavior looks like in your logs."
"Attackers are guessing. You KNOW."

**Connect to the sandwich** (15 sec)
"This is why the guardrail sandwich actually works for you:"
"Input guards work because you can validate against KNOWN GOOD ‚Äî your asset inventory, your approved sources."
"Output guards work because you can verify against OBSERVABLE REALITY ‚Äî did the action achieve the intended state?"

**The caveat ‚Äî be honest** (10 sec)
‚Üí Point to bottom statement, note the "until they're in"
"Now ‚Äî I said 'until they're in.' That's intentional. Once an attacker achieves persistence, this asymmetry erodes. They get dwell time. They enumerate your environment. They read your runbooks."
"The sandwich is most powerful EARLY ‚Äî before they have ground truth parity. Which is why detection speed matters so much."

**Bridge to demos** (10 sec)
"Every demo I'm about to show you exploits this asymmetry while you still have it."
"Config drift ‚Äî keeping your baselines current, not stale."
"Endpoint validation ‚Äî verifying defenses against observable behavior."
"Segmentation testing ‚Äî proving isolation works."
"These only work if you maintain your ground truth. Stale baselines are worse than no baselines ‚Äî they create false confidence."

‚è± ~75 seconds | üëÅ The caveat builds credibility ‚Äî experienced folks will nod instead of mentally composing counterexamples

**Q&A Prep:**
- "What about APTs with dwell time?" ‚Üí "You're right ‚Äî that's why detection speed matters. The sandwich is most powerful when combined with continuous monitoring."
- "Don't attackers test against similar environments?" ‚Üí "Similar, yes. But not YOUR specific config, YOUR baseline deviations, YOUR log correlations. Every environment has unique quirks."` },                   // Slide 9
  { type: 'm365Drift', notes: `**Callback to Bridge** (5 sec)
"Remember what you have that attackers don't? Ground truth. This is the first demo of that principle in action."

**The Architecture** (30 sec)
‚Üí Walk through the 4-step flow left to right
"Your baseline ‚Äî stored configuration snapshot. This is YOUR truth, not Microsoft's defaults."
"Compare ‚Äî pure math. Set difference. What's in current that wasn't in baseline? What's missing? What changed?"
"AI layer ‚Äî notice it says OPTIONAL. GPT-4 just translates GUIDs to human names. It formats the output. It never decides what changed."
"Alert ‚Äî ticket in your PSA, email to your team. Human-readable, actionable."

**The Key Line** (15 sec)
‚Üí Point to the green callout
"GPT-4 summarizes. Math decides. This is the architecture you want. Deterministic core, probabilistic enhancement."
"If someone asks 'could the AI hide a change?' ‚Äî no. Changes are detected and logged before AI touches them."

**Dual Triggers** (15 sec)
"Notice two triggers: cron every 42 minutes, plus real-time webhook from Microsoft's audit log."
"Why both? Microsoft webhooks are best-effort, not guaranteed. Audit logs have documented delays of 5-30 minutes. The cron is your safety net."

**The Example** (10 sec)
"Block Legacy Auth set to Report-Only. This exact drift has been involved in multiple M365 compromises."
"Someone was 'just testing' or 'helping a vendor' and forgot to re-enable. Attackers specifically look for this gap."

**Landing** (5 sec)
"Your baseline. Your rules. AI makes it readable. That's the pattern for every demo that follows."

‚è± ~80 seconds | üëÅ "GPT-4 summarizes, math decides" is the quotable line ‚Äî pause after it

**Q&A Prep:**
- "What if attacker modifies the baseline?" ‚Üí "Critical point. Baseline integrity is the foundation. That's why baseline changes should require approval, not auto-accept."
- "42 minutes is a long gap" ‚Üí "You're right ‚Äî that's the tradeoff between API cost and detection speed. The webhook is your real-time layer."` },                // Slide 10
  { type: 'endpointValidation' },       // Slide 9
  { type: 'networkSeg' },               // Slide 10
  { type: 'alertTriage' },              // Slide 11
  { type: 'evolutionRace' },            // Slide 12

  // ============================================
  // BREAK (15 min)
  // ============================================

  { type: 'break' },                    // Slide 13

  // ============================================
  // PART 3: GOVERNANCE & TRUST (35 min)
  // "How to do this without getting fired"
  // ============================================

  { type: 'governance' },               // Slide 14
  { type: 'shadowAI' },                 // Slide 15
  { type: 'failureModes' },             // Slide 16

  // Slide 17 & 18: Governance content slides (using generic ContentSlide)
  // NOTE: These are now hardcoded in separate slide components if needed
  // For now, temporarily commented as they used generic content structure

  // ============================================
  // PART 4: MONDAY MORNING (30 min)
  // "What you actually do next"
  // ============================================

  { type: 'operationalization' },       // Slide 17
  { type: 'budget' },                   // Slide 18
  { type: 'learningPath' },             // Slide 19
  { type: 'multiTenant' },              // Slide 20
  { type: 'tail' },                     // Slide 21
  { type: 'insurance' },                // Slide 22
  { type: 'takeaways' },                // Slide 23
  { type: 'sources' },                  // Slide 24
  { type: 'closing' }                   // Slide 25
];

// Re-export themes from centralized config
export { themes } from '../config/themes';
