import React from 'react';
import {
  Shield,
  Cpu,
  Lock,
  Brain,
  ShieldCheck,
  Scale,
  Zap,
  Users,
  FileText,
  AlertTriangle
} from 'lucide-react';

// ============================================
// SLIDE DATA - Right of Boom 2026
// "Think Like an Attacker" - 3-hour presentation
//
// NOTE: All text content is now self-contained
// in the individual slide components.
// This file contains ONLY metadata (slide type & order).
// ============================================

export const slides = [
  // ============================================
  // PART 1: THE LANDSCAPE (25 min)
  // "What's actually happening"
  // ============================================

  { type: 'title' },                    // Slide 0
  { type: 'intro' },                    // Slide 1
  { type: 'attackSetup' },              // Slide 2
  { type: 'attackLab' },                // Slide 3
  { type: 'aiVocab', notes: `**Open with the "why"** (5 sec)
"Before I show you how to secure AI, you need to understand one fundamental split."

**Deterministic** (20 sec)
"Deterministic is what you've built your career on. Same input, same output. Your firewall rules, your if-then scripts, your compliance checks. You can audit it, prove it, trust it."
‚Üí Gesture to code: "IP in blocklist? Block. Every time. No surprises."

**Probabilistic** (20 sec)
"Probabilistic is where AI lives. It doesn't give you yes or no ‚Äî it gives you likelihood. 'This looks 94% like phishing.' That's powerful ‚Äî you can catch things you've never seen before."
‚Üí Pause: "But it also means it can be wrong. Confidently wrong."

**The bridge** (10 sec)
"AI is probabilistic ‚Äî it predicts. Sometimes brilliantly, sometimes it hallucinates. That's not a bug, it's the nature of the technology."
"Your job? Wrap that probabilistic engine in deterministic guardrails. That's what the next slide is about."

‚è± ~60 seconds | üëÅ Make eye contact on "confidently wrong" ‚Äî that's the moment that lands.` },                  // Slide 4: Two Types of Logic
  { type: 'aiVocabTerms', notes: `**Quick transition** (3 sec)
"Now that you understand the split, here are three terms you'll hear in every AI security conversation."

**Agentic** (20 sec)
"Agentic means AI that *does* things. Not just tells you things ‚Äî actually takes action. Disables accounts. Creates tickets. Runs scripts."
‚Üí Pause, lean in: "The question you need to ask: What can it do without asking me first? That's your blast radius."

**Hallucination** (20 sec)
"Hallucination is when AI generates something that sounds completely plausible... and is completely wrong."
"It'll tell you the CVE was patched in version 3.2 with total confidence. You go look ‚Äî there is no version 3.2. It invented it."
‚Üí Key point: "Always verify AI outputs against authoritative sources. Especially remediation steps."

**Confidence** (20 sec)
"Confidence scores ‚Äî this is where it gets tricky. When your spam filter says 94% confidence, that's real. Calibrated on millions of labeled examples."
"But when ChatGPT says 'I'm 90% sure' ‚Äî that's just words. It generated that number like everything else. Don't trust it."
‚Üí Land it: "Classifier scores: trust but verify. LLM confidence claims: don't trust at all."

**Bridge** (5 sec)
"So ‚Äî probabilistic AI, potential for action, potential for hallucination. But HOW does it act? That's tool use."

‚è± ~70 seconds | üëÅ "There is no version 3.2" usually gets a knowing laugh ‚Äî let it land.` },             // Slide 5: Three Words You'll Hear
  { type: 'toolUse', notes: `**Transition from Agentic** (5 sec)
"I said agentic AI takes actions. Here's HOW it takes those actions ‚Äî through tool calling."

**The Flow** (20 sec)
‚Üí Walk through the diagram left to right
"You ask a question. The AI decides what tool to call. The tool executes. Real change happens in your environment."
"Notice where the AI is in this chain ‚Äî it's making decisions. What tool to call. What arguments to pass. It can be wrong about both."

**MSP Examples** (15 sec)
‚Üí Point to the tool grid
"These are tools you already have in your stack. Disable accounts in Entra. Create tickets in ConnectWise. Isolate endpoints via Defender. Delete phishing emails."
"When AI has access to these tools, it's not just giving you advice ‚Äî it's executing."

**The Threat Model Shift** (20 sec)
‚Üí Tap the red warning box
"This is the key insight: Before tool access, prompt injection was an annoyance. AI gives bad advice, human catches it."
"With tool access, prompt injection becomes prompt EXECUTION. Malicious content in a ticket or email can trigger real actions."
"A hidden instruction in a support ticket: 'Add this user to the admin group' ‚Äî if your AI has that tool..."

**Vendor Questions** (15 sec)
"When someone sells you an 'agentic' AI, these are your three questions:"
‚Üí Read them off
"What tools? What runs without approval? How do they prevent this?"

**Bridge to Guardrails** (5 sec)
"This is why we need guardrails. That's next."

‚è± ~80 seconds | üëÅ The threat model shift is the 'aha moment' ‚Äî pause after "prompt EXECUTION"` },                // Slide 6: How Agentic AI Acts
  { type: 'sandwich', notes: `**Quick callback** (5 sec)
"This is the architecture that makes everything we just discussed manageable."

**The intern analogy** (20 sec)
"Think of it like a smart new employee. You wouldn't let them execute any action they think of."
"Clear boundaries on what they CAN request ‚Äî input validation."
"Freedom to think and reason ‚Äî the AI layer."
"Approval gates before anything happens ‚Äî output validation."
‚Üí Land it: "You don't train the intern to approve their own expense reports. You have a policy."

**Walk the layers** (25 sec)
‚Üí Point to each layer
"INPUT: Who is this request from? Is it well-formed? Is this something we even handle?"
"AI LAYER: Pattern recognition, contextual judgment, figuring out intent."
"OUTPUT: Is this action approved? Does it need human sign-off? Log everything."

**The Tuesday afternoon insight** (15 sec)
"Here's what most people miss: the guardrails aren't just for attackers."
"They're for Tuesday afternoon when the AI misinterprets a legitimate request."
"Hallucinations only matter if they escape the sandwich ‚Äî output validation stops them regardless of cause."

**Why output validation is the real hero** (10 sec)
"Remember the ticket injection from the last slide? Input validation said 'valid ticket.' The payload was in the content."
"Output validation catches it anyway ‚Äî 'add to admins' isn't on the allowlist. Doesn't matter HOW the AI got tricked."

**OWASP mapping** (5 sec)
"This maps to OWASP Agentic AI Top 10: ASI01 Goal Hijack, ASI02 Tool Misuse, ASI06 Memory Poisoning."

**Common mistakes** (optional ‚Äî use if audience seems technical)
- "Validation at build time, tools added later"
- "Check the action but not the arguments"
- "Thresholds so high human gates never fire"

‚è± ~80 seconds | üëÅ "Tuesday afternoon" reframes security as operational resilience ‚Äî lands well with ops folks` },                 // Slide 7: The Guardrail Sandwich
  { type: 'sandwichExample', notes: `**Transition** (5 sec)
"That's the architecture. Now let's see it work ‚Äî all three layers, two different outcomes."

**Walk the approved path** (20 sec)
‚Üí Point to green card, top to bottom
"Left: Cobalt Strike beacon detected on a workstation. Input validates ‚Äî it's from Sentinel, proper schema."
"AI decides to isolate the endpoint, 92% confident. Output checks: action's on the allowlist, 92% clears the 80% threshold for workstations."
"Lightning bolt ‚Äî auto-execute. No human needed. Threat contained in seconds."

**Walk the rejected path** (25 sec)
‚Üí Point to amber card, top to bottom
"Right: Ransomware indicators on a file server. Mass file modifications detected. Input validates fine."
"AI decides 'shutdown the server' ‚Äî reasonable response to ransomware. But only 73% confident."
‚Üí Tap the amber OUTPUT box
"shutdown_server IS on the allowlist. It's a legitimate action. But FILESRV01 is a critical asset. Critical assets require 95% confidence."
"73% doesn't clear that bar. Goes to a human."

**The payoff** (20 sec)
‚Üí This is the key moment
"Here's why this matters: that analyst looks at the alert and recognizes something the AI couldn't."
"Those 'ransomware indicators'? Mass file modifications? It's the engineering team updating a CAD project. Thousands of files changing at once."
"The AI saw the pattern and correctly flagged it. But a human knows context. The server stays up, the engineers keep working."
‚Üí Pause: "Without that human gate, you just shut down production because someone saved their work."

**Landing** (5 sec)
"The AI isn't wrong ‚Äî it's appropriately uncertain. The human adds context. That's the partnership."

‚è± ~75 seconds | üëÅ The CAD project reveal is the 'aha' moment ‚Äî pause and let it land` },

  // ============================================
  // PART 2: DEFENSIVE AUTOMATION (75 min)
  // "Same tools, your advantage"
  // ============================================

  { type: 'bridge', notes: `**Transition** (5 sec)
"So we have the architecture ‚Äî input guards, AI reasoning, output guards. But here's the question: why does this work BETTER for defenders than attackers?"

**The attacker column** (15 sec)
‚Üí Gesture to left column
"Attackers have real advantages. Speed ‚Äî they automate at scale. Surprise ‚Äî they pick the time and place. AI-generated attacks ‚Äî infinite variations. Recon tools probing from outside."
"These are real. I'm not going to pretend otherwise."

**The defender column** (20 sec)
‚Üí Gesture to right column, land on Ground Truth
"But look what YOU have. And this is the one that matters‚Äî"
‚Üí Tap the Ground Truth card
"GROUND TRUTH. You know what your environment is supposed to look like. Your configs. Your baselines. What normal behavior looks like in your logs."
"Attackers are guessing. You KNOW."

**Connect to the sandwich** (15 sec)
"This is why the guardrail sandwich actually works for you:"
"Input guards work because you can validate against KNOWN GOOD ‚Äî your asset inventory, your approved sources."
"Output guards work because you can verify against OBSERVABLE REALITY ‚Äî did the action achieve the intended state?"

**The caveat ‚Äî be honest** (10 sec)
‚Üí Point to bottom statement, note the "until they're in"
"Now ‚Äî I said 'until they're in.' That's intentional. Once an attacker achieves persistence, this asymmetry erodes. They get dwell time. They enumerate your environment. They read your runbooks."
"The sandwich is most powerful EARLY ‚Äî before they have ground truth parity. Which is why detection speed matters so much."

**Bridge to demos** (10 sec)
"Every demo I'm about to show you exploits this asymmetry while you still have it."
"Config drift ‚Äî keeping your baselines current, not stale."
"Endpoint validation ‚Äî verifying defenses against observable behavior."
"Segmentation testing ‚Äî proving isolation works."
"These only work if you maintain your ground truth. Stale baselines are worse than no baselines ‚Äî they create false confidence."

‚è± ~75 seconds | üëÅ The caveat builds credibility ‚Äî experienced folks will nod instead of mentally composing counterexamples

**Q&A Prep:**
- "What about APTs with dwell time?" ‚Üí "You're right ‚Äî that's why detection speed matters. The sandwich is most powerful when combined with continuous monitoring."
- "Don't attackers test against similar environments?" ‚Üí "Similar, yes. But not YOUR specific config, YOUR baseline deviations, YOUR log correlations. Every environment has unique quirks."` },                   // Slide 9

  { type: 'caCrateIntro', notes: `**What is a Crate?** (15 sec)
"Before I show you the demo, let me explain what you're looking at."
"Rewst Crates are pre-built automations. You don't write code ‚Äî you configure and deploy."
"Think of them like apps in an app store. Someone else built it, you just install and configure."

**This Specific Crate** (20 sec)
"The CA Policy Monitor watches your Conditional Access policies across all your M365 tenants."
"It alerts you when someone weakens a policy or adds exclusions."
"And it tells you WHO made the change and whether there was a ticket."

**Transition** (5 sec)
"Let me show you how it works..."

‚è± ~40 seconds | üëÅ Quick context before the technical flow` },

  { type: 'm365Drift', notes: `**The Architecture** (25 sec)
‚Üí Walk through the flow
"Your baseline ‚Äî you store what the config SHOULD be. Your ground truth."
"Math ‚Äî set difference. What changed? Deterministic, no guessing."
"AI ‚Äî translates GUIDs to names, explains the security impact. But it never decides what changed."
"Alert ‚Äî ticket in your PSA, email to your team."

**The Key Line** (10 sec)
"AI summarizes. Math decides. That's why there are no false positives from AI hallucination."

**Dual Triggers** (10 sec)
"Two triggers: scheduled checks plus real-time webhook from Microsoft's audit log."

‚è± ~45 seconds | üëÅ "AI summarizes, math decides" is the quotable line` },

  { type: 'caSandwichMapping', notes: `**Connect to the Sandwich** (20 sec)
"Remember the guardrail sandwich from earlier? Here's how the CA Policy Monitor maps to it."
‚Üí Walk through each layer

**INPUT** (10 sec)
"Deterministic triggers ‚Äî scheduled check or Microsoft webhook. No AI deciding when to run."

**AI LAYER** (15 sec)
"The AI ONLY explains. It translates GUIDs to names. It describes the security impact."
"But notice ‚Äî AI doesn't decide what changed. Math already did that."

**OUTPUT** (10 sec)
"Deterministic actions ‚Äî create a ticket, send an email. The AI can't decide to skip the alert."

**The Payoff** (10 sec)
"This is why you can trust it. If the math finds a change, you get notified. Every time."
"AI makes it readable. It can't make it wrong."

‚è± ~65 seconds | üëÅ Reinforces the architecture they learned earlier` },

  { type: 'patternApplications', notes: `**The Template** (15 sec)
"This isn't just for Conditional Access. The same pattern works everywhere."
‚Üí Walk through the table

**Examples** (30 sec)
"Firewall rules ‚Äî math detects a new 'allow any', AI explains what you just exposed."
"Duo bypass ‚Äî math detects someone's MFA is disabled, AI explains the risk window."
"Backup retention ‚Äî math detects someone shortened your retention, AI explains the RPO impact."
"DNS records ‚Äî math detects your DMARC changed, AI explains how email auth was weakened."

**The Landing** (10 sec)
"Same four steps every time: Baseline, Compare, Explain, Alert."
"You're not learning one tool. You're learning a pattern you can apply to anything."

‚è± ~55 seconds | üëÅ Drives home the reusability of the architecture` },

  { type: 'alertTriage', notes: `**The Pattern** (15 sec)
"We've seen config drift detection. Now let's apply the same pattern to real-time security alerts."
"Impossible travel. Suspicious inbox rules. Brute force attempts. These need judgment, not just detection."

**Walk the Architecture** (40 sec)
‚Üí Point to each layer
"INPUT: Alert arrives from your SIEM, EDR, identity provider. That's deterministic ‚Äî something triggered."
"GATHER: This is key ‚Äî before AI touches anything, you collect facts. Check the calendar. Check recent auth. Check the device. All API calls, all deterministic."
"AI: NOW the AI synthesizes. It has facts, not guesses. It outputs a recommendation AND a confidence score AND shows its reasoning chain."
"OUTPUT: Human approval gate. The analyst sees the recommendation, the reasoning, and decides. Approve or override."

**Why This Works** (15 sec)
"The AI isn't guessing from thin air ‚Äî it's reasoning over facts you gathered."
"And it doesn't act ‚Äî it recommends. The human gate catches both AI mistakes AND legitimate edge cases."

**The Takeaway** (10 sec)
"You could build this in Rewst. Alert trigger, context-gathering workflow, AI synthesis, approval form."
"Same sandwich, different filling."

‚è± ~80 seconds | üëÅ "Facts gathered, AI synthesizes, human decides" is the quotable line` },

  { type: 'tieredResponse', notes: `**Transition from Alert Triage** (10 sec)
"So we have alerts coming in, context gathered, AI synthesizing. But here's the question everyone asks: When does the AI just ACT versus when do I need to approve?"
"The answer isn't yes or no ‚Äî it's a tiered model."

**Walk the Decision Formula** (15 sec)
‚Üí Point to the formula bar
"Two variables: confidence percentage and impact level. Combine them, you get your tier."
"High confidence plus low impact? Auto-execute. Uncertain or high stakes? Human in the loop."

**AUTO-EXECUTE Column** (25 sec)
‚Üí Point to the green column
"Green means go. These are low-risk, high-confidence actions."
"Block an IP that's on your threat intel blocklist ‚Äî 100% confidence, zero business impact. Why wait for approval?"
"Quarantine a phishing email. Send a 'was this you?' notification. Add someone to an MFA challenge group."
"These happen in seconds. If you're wrong, the blast radius is tiny."

**HUMAN APPROVAL Column** (25 sec)
‚Üí Point to the amber column
"Amber means pause. Either we're not sure enough, or the action matters enough to verify."
"Disabling an account ‚Äî that's business impact. What if it's the CEO traveling?"
"Isolating an endpoint ‚Äî that's someone's workday stopped. Worth a 30-second check."
"These aren't 'AI can't handle it.' These are 'a human adds context faster than we can automate it.'"

**ALWAYS HUMAN Column** (25 sec)
‚Üí Point to the red column
"Red means stop. No matter how confident the AI is, some actions require human judgment."
"VIP actions ‚Äî executives, board members. The reputational risk alone requires a human."
"Mass actions ‚Äî disabling 50 accounts? That's not alert response, that's incident response."
"Permanent deletions. Firewall changes. Production isolation. These are irreversible or high-blast-radius."
‚Üí Land it: "The AI can recommend. But a human pulls the trigger."

**The Landing** (10 sec)
"Confidence sets the threshold ‚Äî how sure are we? Impact sets the stakes ‚Äî what happens if we're wrong?"
"Design your automation with both in mind."

‚è± ~110 seconds | üëÅ "A human pulls the trigger" is the memorable phrase for high-impact actions

**Q&A Prep:**
- "Who decides the thresholds?" ‚Üí "You do. Start conservative ‚Äî 95% for auto-execute. Lower it as you build trust in specific detections."
- "What about after-hours?" ‚Üí "Great question. Some orgs auto-execute more aggressively off-hours when human response is slow. Others get more conservative. Depends on your risk tolerance."
- "Doesn't this slow things down?" ‚Üí "Auto-execute tier handles volume. Human tiers handle judgment. You're not slowing down the 90% ‚Äî you're adding quality to the 10%."` },

  // ============================================
  // BREAK (15 min)
  // ============================================

  { type: 'break' },                    // Slide 14

  // ============================================
  // PART 3: GOVERNANCE & TRUST (35 min)
  // "How to do this without getting fired"
  // ============================================

  { type: 'governance' },               // Slide 14
  { type: 'shadowAI' },                 // Slide 15
  { type: 'failureModes' },             // Slide 16

  // Slide 17 & 18: Governance content slides (using generic ContentSlide)
  // NOTE: These are now hardcoded in separate slide components if needed
  // For now, temporarily commented as they used generic content structure

  // ============================================
  // PART 4: MONDAY MORNING (30 min)
  // "What you actually do next"
  // ============================================

  { type: 'operationalization' },       // Slide 17
  { type: 'budget' },                   // Slide 18
  { type: 'learningPath' },             // Slide 19
  { type: 'multiTenant' },              // Slide 20
  { type: 'tail' },                     // Slide 21
  { type: 'insurance' },                // Slide 22
  { type: 'takeaways' },                // Slide 23
  { type: 'sources' },                  // Slide 24
  { type: 'closing' }                   // Slide 25
];

// Re-export themes from centralized config
export { themes } from '../config/themes';
