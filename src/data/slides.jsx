import React from 'react';
import {
  Shield,
  Cpu,
  Lock,
  Brain,
  ShieldCheck,
  Scale,
  Zap,
  Users,
  FileText,
  AlertTriangle
} from 'lucide-react';

// ============================================
// SLIDE DATA - Right of Boom 2026
// "Think Like an Attacker" - 3-hour presentation
//
// NOTE: All text content is now self-contained
// in the individual slide components.
// This file contains ONLY metadata (slide type & order).
// ============================================

export const slides = [
  // ============================================
  // PART 1: THE LANDSCAPE (25 min)
  // "What's actually happening"
  // ============================================

  { type: 'title' },                    // 000
  { type: 'intro' },                    // 001
  { type: 'aiRiskTension', notes: `**Set up the tension** (5 sec)
"Before we dive in, let's name the elephant in the room."

**Left column - Adoption risks** (25 sec)
‚Üí Gesture to left card
"If you let AI loose in your stack without guardrails..."
"Hallucinated fix pushed to production ‚Äî AI tells your L1 to change a firewall rule. They trust it. It's wrong. Now you're explaining to a client why their VoIP died."
"One bad automation touches 50 tenants before your NOC notices."
"And your techs? They're already pasting client credentials into ChatGPT to debug scripts. That data is gone."

**Right column - Avoidance risks** (25 sec)
‚Üí Gesture to right card
"But refusing to adopt while attackers don't? That's also losing."
"AI-generated phishing is already landing in your clients' inboxes. No grammar mistakes. Personalized from LinkedIn scrapes."
"Your L1 takes 4 hours to triage an alert. The attacker's tooling iterates in 4 seconds."
"Alert volume across your client base doubles every year. You're not doubling headcount."

**The landing** (10 sec)
‚Üí Pause, let them feel squeezed
"Both paths lead somewhere bad."
"The answer isn't ban AI. It's not trust AI blindly either."
"It's harness it ‚Äî with guardrails. That's what we're building today."

‚è± ~65 seconds | üëÅ MSPs feel this tension daily ‚Äî let the pause land before offering the resolution.` },  // 002
  { type: 'attackSetup', notes: `**Set the stakes** (5 sec)
"Before I show you the defenses, you need to understand why the threat landscape changed so fast."

**Walk the left column** (20 sec)
‚Üí Gesture to 2019
"In 2019, launching a real attack required deep skills. Network protocols. Exploit development. Reverse engineering. You needed to understand OS internals."
"This wasn't script kiddie territory. It took YEARS of dedicated learning."

**Walk the right column** (15 sec)
‚Üí Gesture to 2026
"2026. What does it take now?"
‚Üí Pause, let them read it
"Curiosity. And a login to an LLM."
"That's it. The AI handles the rest."

**The punchline** (15 sec)
‚Üí Tap the bottom section
"Time to first attack. Years... to minutes."
"Your nephew who got bored over winter break can now run attacks that would have required a black hat team five years ago."

**MSP reality check** (15 sec)
"For MSPs, this changes everything. The attacker pool exploded from a few thousand skilled hackers to anyone with internet access and curiosity."
"Your clients aren't being targeted by nation-states. They're being targeted by someone who watched a YouTube tutorial and asked ChatGPT to fill in the gaps."

**Bridge to demo** (5 sec)
"I'm going to prove this to you. Let's watch an AI plan an attack in real time."

‚è± ~75 seconds | üëÅ "Curiosity and a login" is the line that lands ‚Äî let the contrast sink in before moving on

**Q&A Prep:**
- "Isn't this fear-mongering?" ‚Üí "Fair question. Let me show you ‚Äî the demo is next."
- "Are script kiddies really a threat to my clients?" ‚Üí "They're the volume play. Your clients won't be breached by APT29 ‚Äî they'll be breached by someone running AI-generated phishing at scale."` },  // 003
  { type: 'attackLab' },                // 004
  { type: 'aiVocab', notes: `**Open with the "why"** (5 sec)
"Before I show you how to secure AI, you need to understand one fundamental split."

**Deterministic** (20 sec)
"Deterministic is what you've built your career on. Same input, same output. Your firewall rules, your if-then scripts, your compliance checks. You can audit it, prove it, trust it."
‚Üí Gesture to code: "IP in blocklist? Block. Every time. No surprises."

**Why Probabilistic?** (10 sec)
"So why do we care about probabilistic systems at all? Because you can't write a rule for every attack that hasn't happened yet."
"Rules only catch what you've already seen. Probabilistic systems can generalize."

**Probabilistic** (20 sec)
"Probabilistic is where AI lives. It doesn't give you yes or no ‚Äî it gives you likelihood. 'This looks 94% like phishing.' That's powerful ‚Äî you can catch things you've never seen before."
‚Üí Pause: "But it also means it can be wrong. Confidently wrong."

**The bridge** (10 sec)
"AI is probabilistic ‚Äî it predicts. Sometimes brilliantly, sometimes it hallucinates. That's not a bug, it's the nature of the technology."
"Your job? Wrap that probabilistic engine in deterministic guardrails. That's what the next slide is about."

‚è± ~65 seconds | üëÅ Make eye contact on "confidently wrong" ‚Äî that's the moment that lands.` },  // 005
  { type: 'aiVocabTerms', notes: `**Quick transition** (3 sec)
"Now that you understand the split, here are three terms you'll hear in every AI security conversation."

**Agentic** (20 sec)
"Agentic means AI that *does* things. Not just tells you things ‚Äî actually takes action. Disables accounts. Creates tickets. Runs scripts."
‚Üí Pause, lean in: "The question you need to ask: What can it do without asking me first? That's your blast radius."

**Hallucination** (20 sec)
"Hallucination is when AI generates something that sounds completely plausible... and is completely wrong."
"It'll tell you the CVE was patched in version 3.2 with total confidence. You go look ‚Äî there is no version 3.2. It invented it."
‚Üí Key point: "Always verify AI outputs against authoritative sources. Especially remediation steps."

**Confidence** (20 sec)
"Confidence scores ‚Äî this is where it gets tricky. When your spam filter says 94% confidence, that's real. Calibrated on millions of labeled examples."
"But when ChatGPT says 'I'm 90% sure' ‚Äî that's just words. It generated that number like everything else. Don't trust it."
‚Üí Land it: "Classifier scores: trust but verify. LLM confidence claims: don't trust at all."

**Bridge** (5 sec)
"So ‚Äî probabilistic AI, potential for action, potential for hallucination. But HOW does it act? That's tool use."

‚è± ~70 seconds | üëÅ "There is no version 3.2" usually gets a knowing laugh ‚Äî let it land.` },  // 006
  { type: 'toolUse', notes: `**Transition from Agentic** (5 sec)
"I said agentic AI takes actions. Here's HOW it takes those actions ‚Äî through tool calling."

**The Flow** (20 sec)
‚Üí Walk through the diagram left to right
"You ask a question. The AI decides what tool to call. The tool executes. Real change happens in your environment."
"Notice where the AI is in this chain ‚Äî it's making decisions. What tool to call. What arguments to pass. It can be wrong about both."

**MSP Examples** (15 sec)
‚Üí Point to the tool grid
"These are tools you already have in your stack. Disable accounts in Entra. Create tickets in ConnectWise. Isolate endpoints via Defender. Delete phishing emails."
"When AI has access to these tools, it's not just giving you advice ‚Äî it's executing."

**The Threat Model Shift** (20 sec)
‚Üí Tap the red warning box
"This is the key insight: Before tool access, prompt injection was an annoyance. AI gives bad advice, human catches it."
"With tool access, prompt injection becomes prompt EXECUTION. Malicious content in a ticket or email can trigger real actions."
"A hidden instruction in a support ticket: 'Add this user to the admin group' ‚Äî if your AI has that tool..."

**Vendor Questions** (15 sec)
"When someone sells you an 'agentic' AI, these are your three questions:"
‚Üí Read them off
"What tools? What runs without approval? How do they prevent this?"

**Bridge to Guardrails** (5 sec)
"This is why we need guardrails. That's next."

‚è± ~80 seconds | üëÅ The threat model shift is the 'aha moment' ‚Äî pause after "prompt EXECUTION"` },  // 007
  { type: 'sandwich', notes: `**Quick callback** (5 sec)
"This is the architecture that makes everything we just discussed manageable."

**The intern analogy** (20 sec)
"Think of it like a smart new employee. You wouldn't let them execute any action they think of."
"Clear boundaries on what they CAN request ‚Äî input validation."
"Freedom to think and reason ‚Äî the AI layer."
"Approval gates before anything happens ‚Äî output validation."
‚Üí Land it: "You don't train the intern to approve their own expense reports. You have a policy."

**Walk the layers** (25 sec)
‚Üí Point to each layer
"INPUT: Who is this request from? Is it well-formed? Is this something we even handle?"
"AI LAYER: Pattern recognition, contextual judgment, figuring out intent."
"OUTPUT: Is this action approved? Does it need human sign-off? Log everything."

**The Tuesday afternoon insight** (15 sec)
"Here's what most people miss: the guardrails aren't just for attackers."
"They're for Tuesday afternoon when the AI misinterprets a legitimate request."
"Hallucinations only matter if they escape the sandwich ‚Äî output validation stops them regardless of cause."

**Why output validation is the real hero** (10 sec)
"Remember the ticket injection from the last slide? Input validation said 'valid ticket.' The payload was in the content."
"Output validation catches it anyway ‚Äî 'add to admins' isn't on the allowlist. Doesn't matter HOW the AI got tricked."

**OWASP mapping** (5 sec)
"This maps to OWASP Agentic AI Top 10: ASI01 Goal Hijack, ASI02 Tool Misuse, ASI06 Memory Poisoning."

**Common mistakes** (optional ‚Äî use if audience seems technical)
- "Validation at build time, tools added later"
- "Check the action but not the arguments"
- "Thresholds so high human gates never fire"

‚è± ~80 seconds | üëÅ "Tuesday afternoon" reframes security as operational resilience ‚Äî lands well with ops folks` },  // 008
  { type: 'sandwichExample', notes: `**Transition** (5 sec)
"That's the architecture. Now let's see it work ‚Äî all three layers, two different outcomes."

**Walk the approved path** (20 sec)
‚Üí Point to green card, top to bottom
"Left: Cobalt Strike beacon detected on a workstation. Input validates ‚Äî it's from Sentinel, proper schema."
"AI decides to isolate the endpoint, 92% confident. Output checks: action's on the allowlist, 92% clears the 80% threshold for workstations."
"Lightning bolt ‚Äî auto-execute. No human needed. Threat contained in seconds."

**Walk the rejected path** (25 sec)
‚Üí Point to amber card, top to bottom
"Right: Ransomware indicators on a file server. Mass file modifications detected. Input validates fine."
"AI decides 'shutdown the server' ‚Äî reasonable response to ransomware. But only 73% confident."
‚Üí Tap the amber OUTPUT box
"shutdown_server IS on the allowlist. It's a legitimate action. But FILESRV01 is a critical asset. Critical assets require 95% confidence."
"73% doesn't clear that bar. Goes to a human."

**The payoff** (20 sec)
‚Üí This is the key moment
"Here's why this matters: that analyst looks at the alert and recognizes something the AI couldn't."
"Those 'ransomware indicators'? Mass file modifications? It's the engineering team updating a CAD project. Thousands of files changing at once."
"The AI saw the pattern and correctly flagged it. But a human knows context. The server stays up, the engineers keep working."
‚Üí Pause: "Without that human gate, you just shut down production because someone saved their work."

**Landing** (5 sec)
"The AI isn't wrong ‚Äî it's appropriately uncertain. The human adds context. That's the partnership."

‚è± ~75 seconds | üëÅ The CAD project reveal is the 'aha' moment ‚Äî pause and let it land` },  // 009

  // ============================================
  // PART 2: DEFENSIVE AUTOMATION (75 min)
  // "Same tools, your advantage"
  // ============================================

  { type: 'bridge', notes: `**Transition** (5 sec)
"So we have the architecture ‚Äî input guards, AI reasoning, output guards. But here's the question: why does this work BETTER for defenders than attackers?"

**The attacker column** (15 sec)
‚Üí Gesture to left column
"Attackers have real advantages. Speed ‚Äî they automate at scale. Surprise ‚Äî they pick the time and place. AI-generated attacks ‚Äî infinite variations. Recon tools probing from outside."
"These are real. I'm not going to pretend otherwise."

**The defender column** (20 sec)
‚Üí Gesture to right column, land on Ground Truth
"But look what YOU have. And this is the one that matters‚Äî"
‚Üí Tap the Ground Truth card
"GROUND TRUTH. You know what your environment is supposed to look like. Your configs. Your baselines. What normal behavior looks like in your logs."
"Attackers are guessing. You KNOW."

**Connect to the sandwich** (15 sec)
"This is why the guardrail sandwich actually works for you:"
"Input guards work because you can validate against KNOWN GOOD ‚Äî your asset inventory, your approved sources."
"Output guards work because you can verify against OBSERVABLE REALITY ‚Äî did the action achieve the intended state?"

**The caveat ‚Äî be honest** (10 sec)
‚Üí Point to bottom statement, note the "until they're in"
"Now ‚Äî I said 'until they're in.' That's intentional. Once an attacker achieves persistence, this asymmetry erodes. They get dwell time. They enumerate your environment. They read your runbooks."
"The sandwich is most powerful EARLY ‚Äî before they have ground truth parity. Which is why detection speed matters so much."

**Bridge to demos** (10 sec)
"Every demo I'm about to show you exploits this asymmetry while you still have it."
"Config drift ‚Äî keeping your baselines current, not stale."
"Endpoint validation ‚Äî verifying defenses against observable behavior."
"Segmentation testing ‚Äî proving isolation works."
"These only work if you maintain your ground truth. Stale baselines are worse than no baselines ‚Äî they create false confidence."

‚è± ~75 seconds | üëÅ The caveat builds credibility ‚Äî experienced folks will nod instead of mentally composing counterexamples

**Q&A Prep:**
- "What about APTs with dwell time?" ‚Üí "You're right ‚Äî that's why detection speed matters. The sandwich is most powerful when combined with continuous monitoring."
- "Don't attackers test against similar environments?" ‚Üí "Similar, yes. But not YOUR specific config, YOUR baseline deviations, YOUR log correlations. Every environment has unique quirks."` },  // 010

  { type: 'caCrateIntro', notes: `**Transition: Introduce the Crate** (15 sec)
"Let's look at a real example of the guardrail sandwich in action."
"This is a Rewst Crate ‚Äî pre-built automation you configure and deploy, no code required."

**Position It** (10 sec)
"This crate uses AI to explain security changes ‚Äî but the AI is sandwiched between deterministic guardrails."
"The next slide shows exactly how it maps to the pattern we just discussed."

**Quick Context** (5 sec)
"Conditional Access policies control who can log in and how. Changes to these policies can create security gaps."
"This crate catches those changes within minutes."

‚è± ~30 seconds | üëÅ Simple transition ‚Äî details on next slide` },  // 011

  { type: 'm365Drift', notes: `**Walk Through the Flow** (60 sec)
‚Üí Point to each numbered step as you explain

**Step 1: TRIGGER**
"Two ways this kicks off. Either a schedule ‚Äî check every 15 minutes ‚Äî or a real-time webhook from Microsoft Graph. When someone touches a Conditional Access policy, Microsoft can push that event to us immediately."

**Steps 2-3: FETCH + COMPARE**
"We pull the current state from Graph API, then compare it to our stored baseline. Pure set math ‚Äî added equals current minus baseline, removed equals baseline minus current. No AI, no guessing. If a policy changed, the math catches it."

**Step 4: TRANSLATE**
"Microsoft returns everything as GUIDs. This step calls Graph to translate those to human-readable names ‚Äî user emails, group names, app names. Still deterministic, just a lookup."

‚Üí Point to the dashed amber box
"Notice everything so far is in the INPUT GUARDRAIL ‚Äî deterministic code. Nothing probabilistic has touched the data yet."

**Step 5: AI ANALYSIS**
‚Üí Point to the purple box
"NOW we involve AI. It receives the diff and explains the security impact in plain English. 'This change allows legacy authentication, bypassing MFA for these users.' But here's the key ‚Äî the AI cannot change what was detected. It only explains."

**Steps 6-7: NOTIFY + UPDATE**
‚Üí Point to the bottom amber box
"Back to deterministic. Ticket gets created in your PSA. Email goes out. Baseline updates for next run. Every single time, same behavior."

**The Quotable Line** (10 sec)
"Math detects. AI explains. You get notified. That's the sandwich ‚Äî and that's why AI hallucination can't cause false positives."

‚è± ~70 seconds | üëÅ Walk the flow top to bottom, emphasize the amber/purple/amber sandwich structure` },  // 012

  { type: 'patternApplications', notes: `**The Template** (15 sec)
"This isn't just for Conditional Access. The same pattern works everywhere."
‚Üí Walk through the table

**Examples** (30 sec)
"Firewall rules ‚Äî math detects a new 'allow any', AI explains what you just exposed."
"Duo bypass ‚Äî math detects someone's MFA is disabled, AI explains the risk window."
"Backup retention ‚Äî math detects someone shortened your retention, AI explains the RPO impact."
"DNS records ‚Äî math detects your DMARC changed, AI explains how email auth was weakened."

**The Landing** (10 sec)
"Same four steps every time: Baseline, Compare, Explain, Alert."
"You're not learning one tool. You're learning a pattern you can apply to anything."

‚è± ~55 seconds | üëÅ Drives home the reusability of the architecture` },  // 013

  { type: 'alertTriage', notes: `**The Pattern** (15 sec)
"We've seen config drift detection. Now let's apply the same pattern to real-time security alerts."
"Impossible travel. Suspicious inbox rules. Brute force attempts. These need judgment, not just detection."

**Walk the Architecture** (40 sec)
‚Üí Point to each layer
"INPUT: Alert arrives from your SIEM, EDR, identity provider. That's deterministic ‚Äî something triggered."
"GATHER: This is key ‚Äî before AI touches anything, you collect facts. Check the calendar. Check recent auth. Check the device. All API calls, all deterministic."
"AI: NOW the AI synthesizes. It has facts, not guesses. It outputs a recommendation AND a confidence score AND shows its reasoning chain."
"OUTPUT: Human approval gate. The analyst sees the recommendation, the reasoning, and decides. Approve or override."

**Why This Works** (15 sec)
"The AI isn't guessing from thin air ‚Äî it's reasoning over facts you gathered."
"And it doesn't act ‚Äî it recommends. The human gate catches both AI mistakes AND legitimate edge cases."

**The Takeaway** (10 sec)
"You could build this in Rewst. Alert trigger, context-gathering workflow, AI synthesis, approval form."
"Same sandwich, different filling."

‚è± ~80 seconds | üëÅ "Facts gathered, AI synthesizes, human decides" is the quotable line` },  // 014

  { type: 'tieredResponse', notes: `**Transition from Alert Triage** (10 sec)
"So we have alerts coming in, context gathered, AI synthesizing. But here's the question everyone asks: When does the AI just ACT versus when do I need to approve?"
"The answer isn't yes or no ‚Äî it's a tiered model."

**Walk the Decision Formula** (15 sec)
‚Üí Point to the formula bar
"Two variables: confidence percentage and impact level. Combine them, you get your tier."
"High confidence plus low impact? Auto-execute. Uncertain or high stakes? Human in the loop."

**AUTO-EXECUTE Column** (25 sec)
‚Üí Point to the green column
"Green means go. These are low-risk, high-confidence actions."
"Block an IP that's on your threat intel blocklist ‚Äî 100% confidence, zero business impact. Why wait for approval?"
"Quarantine a phishing email. Send a 'was this you?' notification. Add someone to an MFA challenge group."
"These happen in seconds. If you're wrong, the blast radius is tiny."

**HUMAN APPROVAL Column** (25 sec)
‚Üí Point to the amber column
"Amber means pause. Either we're not sure enough, or the action matters enough to verify."
"Disabling an account ‚Äî that's business impact. What if it's the CEO traveling?"
"Isolating an endpoint ‚Äî that's someone's workday stopped. Worth a 30-second check."
"These aren't 'AI can't handle it.' These are 'a human adds context faster than we can automate it.'"

**ALWAYS HUMAN Column** (25 sec)
‚Üí Point to the red column
"Red means stop. No matter how confident the AI is, some actions require human judgment."
"VIP actions ‚Äî executives, board members. The reputational risk alone requires a human."
"Mass actions ‚Äî disabling 50 accounts? That's not alert response, that's incident response."
"Permanent deletions. Firewall changes. Production isolation. These are irreversible or high-blast-radius."
‚Üí Land it: "The AI can recommend. But a human pulls the trigger."

**The Landing** (10 sec)
"Confidence sets the threshold ‚Äî how sure are we? Impact sets the stakes ‚Äî what happens if we're wrong?"
"Design your automation with both in mind."

‚è± ~110 seconds | üëÅ "A human pulls the trigger" is the memorable phrase for high-impact actions

**Q&A Prep:**
- "Who decides the thresholds?" ‚Üí "You do. Start conservative ‚Äî 95% for auto-execute. Lower it as you build trust in specific detections."
- "What about after-hours?" ‚Üí "Great question. Some orgs auto-execute more aggressively off-hours when human response is slow. Others get more conservative. Depends on your risk tolerance."
- "Doesn't this slow things down?" ‚Üí "Auto-execute tier handles volume. Human tiers handle judgment. You're not slowing down the 90% ‚Äî you're adding quality to the 10%."` },  // 015

  // ============================================
  // BREAK (15 min)
  // ============================================

  { type: 'break' },                    // 016

  // ============================================
  // PART 2.5: ENDPOINT PROTECTION TESTING (new)
  // "Safely test endpoint detection"
  // ============================================

  { type: 'safeEndpointTesting', notes: `**Tension-Building Opener** (15 sec)
"Welcome back from break."
‚Üí Read the subtitle aloud, let it sink in
"13 categories. 60+ checks. Hundreds of endpoints. How do you validate them all?"
‚Üí Pause. This is the problem statement.

**MITRE ATT&CK Context** (20 sec)
‚Üí Gesture to left card
"MITRE documents what attackers do AND how to stop them."
"Each technique has specific mitigations: registry keys, GPOs, security settings."
"This is the industry standard."

**Workflow Walkthrough** (30 sec)
‚Üí Walk through the 4 steps on the right
"Step 1: Rewst calls your RMM to run a PowerShell script on endpoints."
"Step 2: Script collects JSON with all the security settings."
"Step 3: AI analyzes the results against MITRE recommendations."
"Step 4: Your technician gets prioritized fixes. Not a wall of raw data."

**The Memorable Number** (10 sec)
‚Üí Point to bottom: "60+ MITRE-mapped checks validated per endpoint"
"60 checks. Every one mapped to a MITRE mitigation. Automated."

**Transition** (5 sec)
"What would an attacker check first?"

‚è± ~80 seconds | üëÅ "How do you validate them all?" builds tension. "60 checks" is the retellable number.` },  // 017

  { type: 'mirrorDesign', notes: `**The Complete Picture** (10 sec)
"Here's everything the script checks ‚Äî 75 individual security controls, organized by attack chain."

**Walk the Attack Chain** (90 sec)
‚Üí Point to each row, explain attacker motivation

"Execution ‚Äî First thing attackers check: Can I run code? If PowerShell v2 is enabled, they bypass all modern logging. If AMSI is broken, their scripts run undetected. If macros aren't blocked, one phishing email gets them in."

"Attack Surface Reduction ‚Äî Microsoft's 15 behavioral rules that block things legitimate software never does. Office spawning PowerShell? Blocked. Scripts downloading executables? Blocked. Attackers check these first because ONE disabled rule is a free path in."

"Evasion ‚Äî Can they blind you? If tamper protection is off, they disable Defender in seconds. If event logging is broken, there's no forensic trail. They're not just attacking ‚Äî they're covering tracks."

"Credentials ‚Äî The crown jewels. If LSASS isn't protected, they dump every password in memory with Mimikatz. If WDigest is enabled, passwords are stored in cleartext. One compromised workstation becomes keys to the kingdom."

"Privilege ‚Äî Can they become admin? If UAC is misconfigured, they escalate silently. If AlwaysInstallElevated is on, any MSI runs as SYSTEM. Game over."

"Lateral ‚Äî Can they spread? If SMB signing is off, they relay credentials across the network. If LLMNR is enabled, they poison name resolution and intercept auth. One machine becomes every machine."

"Persistence ‚Äî Can they survive a reboot? AutoRun, startup folders, scheduled tasks, WMI subscriptions ‚Äî attackers plant backdoors everywhere. Miss one, they're back tomorrow."

"Antivirus ‚Äî Does detection actually work? EICAR is the bare minimum ‚Äî if AV can't catch that, it catches nothing. Exclusions are goldmines ‚Äî attackers drop payloads in excluded paths."

"Network ‚Äî Can they talk out? Firewall holes, disabled DNS filtering, open NetBIOS ‚Äî all ways to exfiltrate or establish C2."

"Data ‚Äî Final defenses. No BitLocker means stolen laptops leak everything. No LAPS means one local admin password works everywhere. No Sysmon means you're blind to what happened."

**The Insight** (10 sec)
"This IS the attacker's recon checklist. Same questions they ask when they land."
"We just ask them first ‚Äî and fix the gaps before they find them."

‚è± ~120 seconds | üëÅ Let them scan the pills while you talk ‚Äî the visual density makes the point` },  // 018

  { type: 'powershellCode', notes: `**OPTIONAL DEPTH** ‚Äî Skip if short on time or low technical interest

**Show the Real Code** (60-90 sec)
"For those interested, here's the actual script. No black box."
‚Üí The full script loads with syntax highlighting ‚Äî scroll through if audience wants

**Key sections to show** (as interest dictates)
‚Üí Lines 1-30: Help documentation and parameters
‚Üí Lines 190-300: Antivirus category ‚Äî EICAR test, exclusion audit
‚Üí Lines 590-750: Credential protection ‚Äî LSASS, Credential Guard, WDigest
‚Üí Lines 1360-1580: Lateral movement ‚Äî SMB, RDP, WinRM checks

**The Point** (20 sec)
"Every check is auditable. You can read it, fork it, customize it."
"MIT licensed, no magic, pure PowerShell."

‚è± ~60-90 seconds | üëÅ This is proof/credibility ‚Äî move through quickly unless asked` },  // 019

  { type: 'endpointSandwich', notes: `**Connect to the Architecture** (10 sec)
"Remember the guardrail sandwich from earlier? This is how Safe Sweep implements it."
"Same architecture, applied to endpoint validation."

**Walk the Layers** (45 sec)
‚Üí Point to each layer, top to bottom
"INPUT: PowerShell runs 60+ checks, outputs JSON. Deterministic, read-only, no AI involved."
"AI LAYER: Claude or GPT analyzes the JSON. Correlates findings. Grades severity. Explains in plain English."
‚Üí Pause, tap the AI layer: "But notice ‚Äî AI only processes structured data. It never touches the endpoint."
"OUTPUT: Human reviews the graded report. Approves remediation. Takes action."

**The Trust Callout** (15 sec)
‚Üí Point to the green box at the bottom
"This is the key insight: No AI touches the endpoint."
"PowerShell detects. AI explains. Human acts."

**Why This Matters** (10 sec)
"The AI can hallucinate an explanation ‚Äî that's fixable. It CAN'T hallucinate a detection."
"The detections are deterministic. That's your ground truth."

‚è± ~80 seconds | üëÅ "PowerShell detects. AI explains. Human acts." is the tagline they should remember` },  // 020

  { type: 'safeSweepReportDemo', notes: `**Show the Real Report** (60-90 sec)
"This is the actual output from our lab run. Real data, real findings."

‚Üí Let the audience absorb the report layout
"Executive Summary ‚Äî AI-generated, explains the business impact."
"Critical Findings ‚Äî prioritized by actual risk, not just alphabetical."
"Remediation Steps ‚Äî deterministic, copy-paste commands from validated baselines."

**Key Insight** (15 sec)
"Notice the separation: AI writes the narrative, but the remediation commands come straight from the script."
"No hallucinated PowerShell. No made-up GPO paths."

**Transition** (10 sec)
"This is what your clients receive. Now let's validate these gaps are real with Atomic Red Team..."

‚è± ~90 seconds | üëÅ Let them read the actual report ‚Äî it's real data, not mockup` },  // 021

  // ============================================
  // PART 3: GOVERNANCE & TRUST (35 min)
  // "How to do this without getting fired"
  // ============================================

  { type: 'governance' },               // 022
  { type: 'shadowAI' },                 // 023
  { type: 'aiCreatesLiability' },       // 024
  { type: 'aiEnablesAttacks' },         // 025

  { type: 'aiTabletop', notes: `**Transition from Failure Modes** (10 sec)
"We've talked about how AI can fail. Now let's talk about preparing your team for it."
"How many of you run tabletop exercises? How many include AI scenarios?"

**The Gap Analysis** (30 sec)
‚Üí Walk through the left column
"Traditional tabletops assume things that don't hold anymore."
"Phishing has tells ‚Äî not when AI writes it. Perfect grammar, personalized from LinkedIn scrapes."
"Voice verification works ‚Äî not when the attacker clones your CFO's voice in 3 seconds."
"Data stays where you put it ‚Äî not when your techs paste client data into ChatGPT."
"Clear forensic artifacts ‚Äî AI attacks may leave nothing to find."

**Scenarios to Add** (25 sec)
‚Üí Point to right column
"Shadow AI data leak ‚Äî employee pastes PII into ChatGPT. What's your response?"
"Deepfake CFO call ‚Äî AI-cloned voice authorizes urgent wire transfer. How do you verify?"
"Prompt injection ‚Äî malicious input hijacks your customer-facing AI. Who's liable?"

**The Key Insight** (10 sec)
‚Üí Tap the bottom callout
"Traditional IR assumes reproducibility. LLMs don't comply."
"You can't re-run the prompt and get the same bad output. Your team needs to practice responding to incidents they can't fully explain."

‚è± ~75 seconds | üëÅ "LLMs don't comply" is the memorable punchline` },  // 026

  // ============================================
  // PART 4: MONDAY MORNING (30 min)
  // "What you actually do next"
  // ============================================

  { type: 'operationalization' },       // 027
  { type: 'tail' },                     // 028
  { type: 'insurance' },                // 029
  { type: 'sources' },                  // 030
  { type: 'closing' }                   // 031
];

// Re-export themes from centralized config
export { themes } from '../config/themes';
